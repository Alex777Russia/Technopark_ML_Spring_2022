{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <center><img src=\"images/header1.png\" width=400></center> </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<h1><center>Основы машинного обучения</center></h1>\n",
    "<hr>\n",
    "<h2><center>Методы обучения без учителя: Кластеризация</center></h2>\n",
    "<h3><center>Шестаков Андрей</center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T14:53:44.411024Z",
     "start_time": "2021-11-10T14:53:43.139546Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T14:53:44.852620Z",
     "start_time": "2021-11-10T14:53:44.412259Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-talk')\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "# Для кириллицы на графиках\n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "try:\n",
    "    from ipywidgets import interact, IntSlider, fixed, FloatSlider\n",
    "except ImportError:\n",
    "    print(u'Так надо')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Методы обучение без учителя (Unsupervised)\n",
    "\n",
    "* В чем отличие от Supervised методов?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Кластеризация\n",
    "* Уменьшение размерности\n",
    "    * Метод главных компонент\n",
    "    * Многомерное шкалирование\n",
    "    * Тематические модели*\n",
    "* Поиск ассоциативных правил"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Кластеризация\n",
    "\n",
    "Основная задача кластерного анализа — разбиение исходного набора объектов на группы (кластеры) таким образом, чтобы объекты в группе были похожи друг на друга, а объекты из разных групп - отличались.\n",
    "\n",
    "<center><img src=\"https://i.ytimg.com/vi/zPJtDohab-g/maxresdefault.jpg\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Цели кластерного анализа\n",
    "\n",
    "* **Поиск структуры** в данных и ее **интерпретация**\n",
    "* Поиск аномальных объектов\n",
    "* Детальный анализ отдельных кластеров\n",
    "* Формирование признаков на основе кластеризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Use Case: Telegram Clustering Contest\n",
    "1. Traverse an input directory and parse all HTML files (articles) in it with news content\n",
    "2. Detect article language and filter out articles which are not in English or Russian\n",
    "3. Classify articles into one or several of 7 categories: society, economy, technology, sports, entertainment, science, other\n",
    "4. Filter out articles which are not news (e.g. how-tos, tips, encyclopedic content)\n",
    "5. Group articles into threads. Thread is just a collection of articles about the same event\n",
    "6. Sort articles within a thread by relevance\n",
    "7. Sort threads by importance\n",
    "\n",
    "2nd Place solution [description](https://medium.com/@alexkuznetsov/2nd-place-solution-for-telegram-data-clustering-contest-f28d55b98d30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Группы методов\n",
    "\n",
    "* Методы основанные на прототипах\n",
    "    * Каждый кластер ассоциируется с виртуальрным \"эталонным\" объектом\n",
    "* Иерархические методы\n",
    "    * Не простое разбиение на целая иерархия\n",
    "* Плотностные методы\n",
    "    * Ищем плотные скопления точек в признаковом пространстве\n",
    "* Вероятностные методы\n",
    "    * Предполагаем, что данные порождены некоторой смесью вероятностных распределений\n",
    "* Спектральные методы\n",
    "    * Испольюзуем замечательные спектральные свойства разных матриц\n",
    "* Сеточные методы\n",
    "    * Бьем признаковое пространство на сегменты\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Алгоритм k-means\n",
    "### Неформальное [демо](https://www.naftaliharris.com/blog/visualizing-k-means-clustering/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Алгоритм k-means\n",
    "\n",
    "* Дано множество объектов $X = \\{x_1, x_2, \\dots, x_N\\}$\n",
    "* Кластер $C_k \\Leftrightarrow \\text{ центройд } \\mu_k$\n",
    "* Объект $x_i \\in C_k \\Leftrightarrow \\mu_k = \\arg \\min\\limits_{\\mu_j} \\|x_i - \\mu_j \\|^2$\n",
    "* Надо найти такое разбиение на $K$ кластеров, чтобы минизировать\n",
    "$$ L(C) = \\sum_{k=1}^K\\sum_{i\\in C_k} ||x_i - \\mu_k||^2 \\rightarrow \\min\\limits_C $$\n",
    "$$\\mu_k = \\frac{1}{|C_k|} \\sum _{x_n \\in C_k} x_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Метод $k$-средних является итеративным алгоритмом разбиения множества объектов на $K$ кластеров "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Алгоритм k-means\n",
    "1. Выбрать $K$ начальных центроидов случайным образом  $\\rightarrow \\mu_k, \\ k=1\\dots K$\n",
    "2. Для каждой точки из датасета присвоить кластер, соответствующий ближайшему центроиду\n",
    "$$C_k = \\{x_n : ||x_n - \\mu_k||^2 \\leq ||x_n - \\mu_l||^2 \\quad \\forall l \\neq k \\} $$\n",
    "3. Обновить центройды: \n",
    "$$\\mu_k = \\frac{1}{|C_k|} \\sum _{x_n \\in C_k} x_n$$\n",
    "4. Повторять 2 и 3 до тех пор, пока изменения перестанут быть существенными \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/Kmeans_animation.gif' width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Основные факторы\n",
    "* Начальная инициализация центройдов\n",
    "* Количество кластеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Kак выбрать K?\n",
    "\n",
    "* Не пользоваться обычным k-means (X-means, ik-means)\n",
    "* Посмотреть на меры качества кластеризации\n",
    "* Воспользоваться эвристиками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Elbow method (Метод локтя)\n",
    "\n",
    "* Критерий минимизации k-means\n",
    "$$ L(C) = \\sum_{k=1}^K\\sum_{i\\in C_k} ||x_i - \\mu_k||^2 \\rightarrow \\min\\limits_C $$\n",
    "* Давайте возьмем всевозможные $K$, для каждого запустим алгоритм, посчитаем на результате $L(C)$ и выберем минимум!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Ничего не выйдет... Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T14:53:45.805294Z",
     "start_time": "2021-11-10T14:53:44.853653Z"
    },
    "code_folding": [
     3,
     20,
     34,
     40
    ],
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X, y = make_blobs(n_samples=500,\n",
    "                  n_features=2,\n",
    "                  centers=4,\n",
    "                  cluster_std=1,\n",
    "                  center_box=(-10.0, 10.0),\n",
    "                  shuffle=True,\n",
    "                  random_state=1) \n",
    "\n",
    "\n",
    "crit = []\n",
    "\n",
    "for k in range(2, 8):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=1).fit(X)\n",
    "    crit.append(np.sqrt(kmeans.inertia_))\n",
    "    \n",
    "def elbow_demo(k=2):\n",
    "    \n",
    "    X, y = make_blobs(n_samples=500,\n",
    "                  n_features=2,\n",
    "                  centers=4,\n",
    "                  cluster_std=1,\n",
    "                  center_box=(-10.0, 10.0),\n",
    "                  shuffle=True,\n",
    "                  random_state=1) \n",
    "    \n",
    "    kmeans = KMeans(n_clusters=k, random_state=1).fit(X)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    \n",
    "    ax[0].scatter(X[:,0], X[:,1], c=kmeans.labels_)\n",
    "    \n",
    "    ax[0].scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n",
    "                  marker='o', c=\"white\", alpha=1, s=200)\n",
    "    \n",
    "    ax[0].set_xlabel('$x_1$')\n",
    "    ax[0].set_ylabel('$x_2$')\n",
    "\n",
    "    for i, c in enumerate(kmeans.cluster_centers_):\n",
    "        ax[0].scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50)\n",
    "        \n",
    "    ax[1].plot(range(2,8), crit, marker='s')\n",
    "    \n",
    "    ax[1].set_xlabel('$k$')\n",
    "    ax[1].set_ylabel('$L^{(k)}(C)$')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Elbow method (Метод локтя)\n",
    "\n",
    "* Выбирают такое $k$, после которого функционал $L(C)$ уменьшается не слишком быстро\n",
    "* Чуть более формально:\n",
    "$$ D(k) = \\frac{|L^{(k)}(C) - L^{(k+1)}(C)|}{|L^{(k-1)}(C) - L^{(k)}(C)|} \\quad \\text{\"невелико\"} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T15:36:52.453729Z",
     "start_time": "2021-11-10T15:36:52.227961Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot = interact(elbow_demo, k=IntSlider(min=2,max=8,step=1,value=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Важно!\n",
    "* Эвристика и меры качества клатеризации носят лишь рекомендательный характер!\n",
    "* Если они ничего не дают, то лучше ориентироваться на свои знания в предметной области\n",
    "* Или \"выжать\" из полученной кластеризации максимум\n",
    "    * *3 из 5 полученных кластеров интерпретируются - и то хорошо*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Начальная инициализация центройдов\n",
    "* Выбрать координаты $K$ случайных объектов из датасета\n",
    "    * Производить случайные запуски много раз и выбрать наиболее оптимальную инициализацию\n",
    "* Использовать результат другой кластеризации на $K$ кластеров\n",
    "* k-means++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### K-means++\n",
    "* Первый центройд выбираем случайным образом из объектов датасета\n",
    "* Для каждой точки рассчитываем расстояние $d_{\\min}(x_i) = \\min_{\\mu_j} \\|x_i - \\mu_j\\|^2$\n",
    "* Точка назначается следующим центройдом с вероятностью $p(x_i) \\propto d_{\\min}(x_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T14:53:46.178115Z",
     "start_time": "2021-11-10T14:53:46.171963Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def demo_kmpp(iters=1):\n",
    "\n",
    "    X, y = make_blobs(n_samples=550, cluster_std=1.5, n_features=2, centers=5, random_state=12345)\n",
    "\n",
    "    X_grid1, X_grid2 = np.meshgrid(np.linspace(-12, 18, 500),\n",
    "                                   np.linspace(-11, 8, 500))\n",
    "\n",
    "    XX = np.c_[X_grid1.flatten(), X_grid2.flatten()]\n",
    "    np.random.seed(1)\n",
    "    centroids = np.empty((0, 2))\n",
    "\n",
    "    for i in range(iters):\n",
    "        if i == 0:\n",
    "            d = np.ones_like(y, dtype=float)\n",
    "        else:\n",
    "            d = pairwise_distances(X, centroids, metric='euclidean').min(axis=1)\n",
    "        weights = d/d.sum()\n",
    "\n",
    "        centroid_idx = np.random.choice(X.shape[0], size=1, replace=False, p=weights)[0]\n",
    "        centroids = np.r_[centroids, X[centroid_idx, np.newaxis]]\n",
    "\n",
    "    d_grid = pairwise_distances(XX, centroids, metric='euclidean').min(axis=1)\n",
    "\n",
    "    d_grid = d_grid.reshape(X_grid1.shape)\n",
    "    d_grid = d_grid/d_grid.max()\n",
    "\n",
    "    levels = np.linspace(0, 1, 100)\n",
    "\n",
    "    plt.contourf(X_grid1, X_grid2, d_grid, cmap=plt.cm.Blues, alpha=0.7, levels=levels)\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=100)\n",
    "\n",
    "    centers = centroids\n",
    "    \n",
    "    plt.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                c=\"white\", alpha=1, s=500, edgecolor='k')\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        plt.scatter(c[0], c[1], marker='$%d$' % (i+1), alpha=1,\n",
    "                    s=100, edgecolor='k')\n",
    "\n",
    "    plt.xlabel('$x_1$', fontsize=15)\n",
    "    plt.ylabel('$x_2$', fontsize=15)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T15:43:54.718435Z",
     "start_time": "2021-11-10T15:43:54.346295Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "interact(demo_kmpp, iters=IntSlider(min=1,max=6,step=1,value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Резюме\n",
    "\n",
    "* Метод k-средних – жадный итеративный алгоритм\n",
    "* Зависит от начальных центройдов и их количества\n",
    "\n",
    "#### Преимущества\n",
    "* Прост как пробка\n",
    "* Имеет множество модификаций\n",
    "* Интерпретация кластеров через центройды"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Недостатки\n",
    "\n",
    "* Подразумевает выпуклые кластеры\n",
    "<center><img src='images/kmeans_2moons.png' width=800></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Всегда* на выходе будет k кластеров\n",
    "<center><img src='images/kmeans_digits.png' width=800></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='images/kmeans-guys.jpeg'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Алгоритмы, основанные на плотности\n",
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Хотелось бы...\n",
    "\n",
    "* Получить кластеры высокой плотности, разделеные участками низкой плотности\n",
    "\n",
    "<center><img src='images/dbscan.png'></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Основная идея\n",
    "\n",
    "* Для каждой точки кластера её окрестность заданного радиуса $\\epsilon$ должна содержать не менее некоторого числа точек `min_pts`. \n",
    "* C такой точки можно начать расширение \"плотного\" кластера \n",
    "    * то есть каждая точка в $\\epsilon$ окрестности будет добавляться в кластер\n",
    "    * ее соседи тоже будут проверяться на критерий `min_pts`\n",
    "* Расширение текущего кластера закончится, когда объекты перестанут удовлетворять условию `min_pts`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Demo\n",
    "Иногда, вместо тысячи слов, лучше один раз посмотреть, как он работает. Но с небольшими комментариями)\n",
    "\n",
    "\n",
    "[Тык](https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Types of points\n",
    "* Core point: точки, в $\\varepsilon$-окрестности которых $\\ge \\texttt{min_pts}$ точек\n",
    "* Border point: не core, но содержит хотя бы 1 core точку в $\\varepsilon$-окрестности\n",
    "* Noise point: ни то ни се\n",
    "<center><img src='images/dbscan_points_types.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## DBSCAN\n",
    "\n",
    "```{C}\n",
    "1.function dbscan(X, eps, min_pts):\n",
    "2.\tinitialize NV = X # not visited objects\t\n",
    "3.\tfor x in NV:\n",
    "4.\t\tremove(NV, x) # mark as visited\n",
    "5.\t\tnbr = neighbours(x, eps) # set of neighbours\n",
    "6.\t\tif nbr.size < min_pts:\n",
    "7.\t\t\tmark_as_noise(x)\n",
    "8.\t\telse:\n",
    "9.\t\t\tC = new_cluster() \n",
    "10.\t\t\texpand_cluster(x, nbr, C, eps, min_pts, NV)\n",
    "11.\t\t\tyield C\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##  expand_cluster\n",
    "\n",
    "```{C}\n",
    "1. function expand_cluster(x, nbr, C, eps, min_pts, NV):\n",
    "2.\tadd(x, C)\n",
    "3.\tfor x1 in nbr:\n",
    "4.\t\tif x1 in NV: # object not visited\n",
    "5.\t\t\tremove(NV, x1) # mark as visited\n",
    "6.\t\t\tnbr1 = neighbours(x1, eps)\n",
    "7.\t\t\tif nbr1.size >= min_pts:\n",
    "8.\t\t\t\t# join sets of neighbours\n",
    "9.\t\t\t\tmerge(nbr, nbr_1) \n",
    "10.\t\tif x1 not in any cluster:\n",
    "11.\t\t\tadd(x1, C)\t\t\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T14:54:03.959621Z",
     "start_time": "2021-11-10T14:54:03.947592Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "data = np.loadtxt('data/flame.txt')\n",
    "X_data = data[:, :2]\n",
    "\n",
    "def dbscan_demo(eps=1, min_pts=5):\n",
    "    \n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_pts).fit(X_data)\n",
    "    \n",
    "    labels = dbscan.labels_\n",
    "    \n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.scatter(X_data[:,0], X_data[:, 1], c=labels)\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T14:54:05.147604Z",
     "start_time": "2021-11-10T14:54:05.027900Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "interact(dbscan_demo, eps=FloatSlider(min=0.1, max=10, step=0.05, value=1), min_pts=IntSlider(min=2, max=15, step=1, value=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Итог\n",
    "\n",
    "#### Преимущества\n",
    "* Не требует $K$\n",
    "* Кластеры произвольной формы\n",
    "* Учитывает выбросы\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Недостатки\n",
    "* Не работает при различных плотностях кластеров\n",
    "* Не всегда выявит кластеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/diff-dens.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Оценка качества кластеризаци"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Оценка качества кластеризации при известном groud truth\n",
    "\n",
    "Пусть $\\hat{\\pi}$ - это полученное разбиение на кластеры, а $\\pi^*$ - ground truth. \n",
    "\n",
    "<center><img src='http://web.cse.ohio-state.edu/~stiff.4/cse3521/images/iris-true-class-sepal.png' width=800></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Adjusted Rand Index\n",
    "\n",
    "$$ \\text{Rand}(\\hat{\\pi},\\pi^*) = \\frac{a + d}{a + b + c + d} \\text{,}$$\n",
    "где \n",
    "* $a$ количество пар объектов, находящихся в одинаковых кластерах в $\\hat{\\pi}$ и\n",
    "$\\pi^*$, \n",
    "* $b$ ($c$) количество пар объектов в одном и том же кластере в  $\\hat{\\pi}$ ($\\pi^*$), но в разных в  $\\pi^*$ ($\\hat{\\pi}$)\n",
    "* $d$ количество пар объектов в разных кластерах в $\\hat{\\pi}$ и $\\pi^*$\n",
    "\n",
    "<center><img src='images/rand1.png' width=700></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Индекс Жаккара\n",
    "$$ Jac(\\hat{\\pi}, \\pi^*) = \\frac{a}{a + b + c}$$\n",
    "\n",
    "#### Точность, полнота и F-мера\n",
    "$$ Precision(\\hat{\\pi}, \\pi^*) = \\frac{a}{a + b} $$\n",
    "$$ Recall(\\hat{\\pi}, \\pi^*) = \\frac{a}{a + c} $$\n",
    "$$ F-measure(\\hat{\\pi}, \\pi^*) = \\frac{2Precision \\cdot Recall}{Precision + Recall} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Меры валидности кластеров (no ground truth)\n",
    "\n",
    "* Измеряют полученое разбиения по отношению к качествам хорошей кластеризации\n",
    "    * Компактность объектов внутри кластера\n",
    "    * Разделимость кластеров друг от друга\n",
    "    \n",
    "Про различные меры качества кластризации и меры валидности кластеров в sklearn можно почитать [тут](https://scikit-learn.org/stable/modules/clustering.html#clustering-evaluation) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##### Критерий Silhouette\n",
    "\n",
    "Пусть дана кластеризация в $K$ кластеров, и объект $i$ попал в $C_k$\n",
    "\n",
    "* $a(i)$ -- среднее расстояние от $i$ объекта до объектов из $C_k$\n",
    "* $b(i) = min_{j \\neq k} b_j(i)$,  где $b_j(i)$ -- среднее расстояние от $i$ объекта до объектов из $C_j$\n",
    "$$\n",
    "silhouette(i) = \\frac{b(i) - a(i)}{\\max(a(i), b(i))}\n",
    "$$\n",
    "Средний silhouette для всех точек из $\\mathbf{X}$ является критерием качества кластеризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/sil1.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/sil2.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Важно!\n",
    "* Эвристики и меры качества клатеризации носят лишь рекомендательный характер!\n",
    "* Если они ничего не дают, то лучше ориентироваться на свои знания в предметной области\n",
    "* Или \"выжать\" из полученной кластеризации максимум\n",
    "    * *3 из 5 полученных кластеров интерпретируются - и то хорошо*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Литература\n",
    "* [Mohammed J. Zaki, Ch3](https://www.amazon.com/Data-Mining-Analysis-Fundamental-Algorithms/dp/0521766338)\n",
    "* [Jure Leskovec, Anand Rajaraman, Jeffrey D. Ullman, Ch7](http://www.mmds.org/)\n",
    "* [Andrew R. Webb, Keith D. Copsey, Ch11](http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0470682272.html)\n",
    "* [Tutorial on spectral clustering](https://arxiv.org/pdf/0711.0189.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Вопросы?\n",
    "\n",
    "### Пожалуйста, напишите отзыв о лекции"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Слайд-шоу",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "livereveal": {
   "theme": "serif",
   "transition": "concave"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "513px",
    "width": "253px"
   },
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "toc_position": {
   "height": "32px",
   "left": "9px",
   "right": "1379px",
   "top": "33px",
   "width": "212px"
  },
  "widgets": {
   "state": {
    "54e80d57f79b4bfc934a2b84cf5fe7ba": {
     "views": [
      {
       "cell_index": 47
      }
     ]
    },
    "5fb17a3592634a4fba98446dacd6db43": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "6f6f6ce7b81743308b92966f225862a8": {
     "views": [
      {
       "cell_index": 34
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
